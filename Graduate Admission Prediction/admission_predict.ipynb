{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>330</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>321</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>308</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>302</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>323</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "5        330          115                  5  4.5   3.0  9.34         1   \n",
       "6        321          109                  3  3.0   4.0  8.20         1   \n",
       "7        308          101                  2  3.0   4.0  7.90         0   \n",
       "8        302          102                  1  2.0   1.5  8.00         0   \n",
       "9        323          108                  3  3.5   3.0  8.60         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  \n",
       "5              0.90  \n",
       "6              0.75  \n",
       "7              0.68  \n",
       "8              0.50  \n",
       "9              0.45  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_scaled=scaler.fit_transform(xtrain)\n",
    "xtest_scaled=scaler.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58      , 0.64285714, 0.5       , ..., 0.625     , 0.71794872,\n",
       "        0.        ],\n",
       "       [0.52      , 0.64285714, 0.5       , ..., 0.875     , 0.63461538,\n",
       "        1.        ],\n",
       "       [0.8       , 0.82142857, 1.        , ..., 0.5       , 0.81410256,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.48      , 0.53571429, 0.25      , ..., 0.75      , 0.47115385,\n",
       "        0.        ],\n",
       "       [0.68      , 0.64285714, 0.75      , ..., 0.75      , 0.75320513,\n",
       "        1.        ],\n",
       "       [0.8       , 0.78571429, 0.75      , ..., 0.5       , 0.75961538,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120 (480.00 Byte)\n",
      "Trainable params: 120 (480.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\newpy\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1798: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 27ms/step - loss: 0.8972 - accuracy: 0.0000e+00 - val_loss: 0.8817 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7851 - accuracy: 0.0000e+00 - val_loss: 0.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6841 - accuracy: 0.0000e+00 - val_loss: 0.6594 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5851 - accuracy: 0.0000e+00 - val_loss: 0.5521 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.0000e+00 - val_loss: 0.4506 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.0000e+00 - val_loss: 0.3606 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.0000e+00 - val_loss: 0.2815 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2603 - accuracy: 0.0000e+00 - val_loss: 0.2168 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2011 - accuracy: 0.0000e+00 - val_loss: 0.1634 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1519 - accuracy: 0.0000e+00 - val_loss: 0.1197 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 0.0000e+00 - val_loss: 0.0848 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.0000e+00 - val_loss: 0.0589 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.0000e+00 - val_loss: 0.0407 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.0000e+00 - val_loss: 0.0284 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.0000e+00 - val_loss: 0.0206 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0290 - accuracy: 0.0000e+00 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.0000e+00 - val_loss: 0.0138 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0211 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0189 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(xtrain_scaled,ytrain,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6740356065549896"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(ytest,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x287a77a1df0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
